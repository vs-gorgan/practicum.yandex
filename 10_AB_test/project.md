# Описание проекта

Вы работаете в стартапе, который продаёт продукты питания. Нужно разобраться, как ведут себя пользователи вашего мобильного приложения.

Изучите воронку продаж. Узнайте, как пользователи доходят до покупки. Сколько пользователей доходит до покупки, а сколько — «застревает» на предыдущих шагах? На каких именно?

После этого исследуйте результаты A/A/B-эксперимента. Дизайнеры захотели поменять шрифты во всём приложении, а менеджеры испугались, что пользователям будет непривычно. Договорились принять решение по результатам A/A/B-теста. Пользователей разбили на 3 группы: 2 контрольные со старыми шрифтами и одну экспериментальную — с новыми. Выясните, какой шрифт лучше.

Создание двух групп A вместо одной имеет определённые преимущества. Если две контрольные группы окажутся равны, вы можете быть уверены в точности проведенного тестирования. Если же между значениями A и A будут существенные различия, это поможет обнаружить факторы, которые привели к искажению результатов. Сравнение контрольных групп также помогает понять, сколько времени и данных потребуется для дальнейших тестов.

В случае общей аналитики и A/A/B-эксперимента работайте с одними и теми же данными. В реальных проектах всегда идут эксперименты. Аналитики исследуют качество работы приложения по общим данным, не учитывая принадлежность пользователей к экспериментам.

**Описание данных**

Каждая запись в логе — это действие пользователя, или событие.

- `EventName` — название события;
- `DeviceIDHash` — уникальный идентификатор пользователя;
- `EventTimestamp` — время события;
- `ExpId` — номер эксперимента: 246 и 247 — контрольные группы, а 248 — экспериментальная.

### 1. Откройте файл с данными и изучите общую информацию
```
# импортируем библиотеку обработки и анализа структурированных данных
import pandas as pd
pd.set_option('display.max_colwidth', None)

# импортируем библиотеку для визуализации данных двумерной и трёхмерной графикой
import matplotlib.pyplot as plt

# импортируем библиотеку библиотеку для визуализации данных
# https://habr.com/ru/company/otus/blog/588190/?ysclid=la5ka4qvdj473949173
import plotly.graph_objects as go
import plotly.express as px

# импортируем библиотеку математических вычислений
import numpy as np

# импортируем модуль для работы с датой и временем
import datetime as dt

# импортируем статистические функции
import scipy.stats as stats

# импортируем библиотеку для создания статистических графиков
import seaborn as sns

# импортируем библиотеку с математическими функциями
import math as mth
```
```
# данные из файла logs_exp сохраним в переменную df, установим разделитель \
df = pd.read_csv('/datasets/logs_exp.csv', sep='\t')
```
```
# посмотрим датафрейм
df
```
|        |               EventName |        DeviceIDHash | EventTimestamp | ExpId |
|-------:|------------------------:|--------------------:|---------------:|------:|
|    0   | MainScreenAppear        | 4575588528974610257 | 1564029816     | 246   |
|    1   | MainScreenAppear        | 7416695313311560658 | 1564053102     | 246   |
|    2   | PaymentScreenSuccessful | 3518123091307005509 | 1564054127     | 248   |
|    3   | CartScreenAppear        | 3518123091307005509 | 1564054127     | 248   |
|    4   | PaymentScreenSuccessful | 6217807653094995999 | 1564055322     | 248   |
|   ...  | ...                     | ...                 | ...            | ...   |
| 244121 | MainScreenAppear        | 4599628364049201812 | 1565212345     | 247   |
| 244122 | MainScreenAppear        | 5849806612437486590 | 1565212439     | 246   |
| 244123 | MainScreenAppear        | 5746969938801999050 | 1565212483     | 246   |
| 244124 | MainScreenAppear        | 5746969938801999050 | 1565212498     | 246   |
| 244125 | OffersScreenAppear      | 5746969938801999050 | 1565212517     | 246   |

`244126 rows × 4 columns`
```
df.info()
```
```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 244126 entries, 0 to 244125
Data columns (total 4 columns):
 #   Column          Non-Null Count   Dtype 
---  ------          --------------   ----- 
 0   EventName       244126 non-null  object
 1   DeviceIDHash    244126 non-null  int64 
 2   EventTimestamp  244126 non-null  int64 
 3   ExpId           244126 non-null  int64 
dtypes: int64(3), object(1)
memory usage: 7.5+ MB
```
Получили почти 250 тыс строк. Требуется переименование колонок, изменене типов данных.

### 2. Подготовьте данные

**2.1  Замените названия столбцов на удобные для вас**
```
df = df.rename(columns = {'EventName': 'event', 'DeviceIDHash': 'user_id', 'EventTimestamp': 'event_time', 'ExpId': 'group'})
```
**2.2  Проверьте пропуски и типы данных. Откорректируйте, если нужно**
```
# посмотрим пропуски
df.isna().sum()
```
```
event         0
user_id       0
event_time    0
group         0
dtype: int64
```
Пропуски отсутствуют.
```
# подсчёт явных дубликатов
df.duplicated().sum()
```
`413`   

Присутствуют задублированные строки. Удалим их
```
# удаление явных дубликатов
df = df.drop_duplicates()
```
**2.3  Добавьте столбец даты и времени, а также отдельный столбец дат**
```
# преобразуем UNIX epoch в datetime64
df['datetime'] = pd.to_datetime(
    df['event_time'], unit='s'
)

# создадим столбец с датой
df['date'] = pd.to_datetime(
    df['datetime']) \
        .dt.date \
        .astype('datetime64')

df.head(1)
```
|   |            event |             user_id | event_time | group |            datetime |       date |
|--:|-----------------:|--------------------:|-----------:|------:|--------------------:|-----------:|
| 0 | MainScreenAppear | 4575588528974610257 | 1564029816 | 246   | 2019-07-25 04:43:36 | 2019-07-25 |

### 3.  Изучите и проверьте данные

**3.1  Сколько всего событий в логе?**
```
# посмотрим виды событий и их количество
df['event'].value_counts()
```
```
MainScreenAppear           119101
OffersScreenAppear          46808
CartScreenAppear            42668
PaymentScreenSuccessful     34118
Tutorial                     1018
Name: event, dtype: int64
```
У нас пять типов событий:
- `MainScreenAppear` - пользователь попал на главный экран
- `OffersScreenAppear` - экран оформления заказа
- `CartScreenAppear`- экран корзины
- `PaymentScreenSuccessful` - уведомление об успешной оплате
- `Tutorial` - помощь / руководство
```
events = df['event'].count()
print('Всего событий в логе =', events)
```
```
Всего событий в логе = 243713
```
**3.2  Сколько всего пользователей в логе?**
```
users = len(df['user_id'].unique())
print('Количество пользователей =', users)
```
```
Количество пользователей = 7551
```
**3.3  Сколько в среднем событий приходится на пользователя?**
```
print('Среднее количество событий на пользователя =', int(events/users))
```
```
Среднее количество событий на пользователя = 32
```
```
# методом describe, посмотрим как распределено количество событий у пользователей
number_of_events = pd.DataFrame(df.groupby('user_id')['event'].count())
display(number_of_events.describe())
print()
print('Контрольная группа 1')
print(df.query('group == 246').groupby('user_id')['event'].count().describe())
print()
print('Контрольная группа 2')
print(df.query('group == 247').groupby('user_id')['event'].count().describe())
print()
print('Экспериментальная группа')
print(df.query('group == 248').groupby('user_id')['event'].count().describe())
```
|       |       event |
|------:|------------:|
| count | 7551.000000 |
|  mean | 32.275593   |
|  std  | 65.154219   |
|  min  | 1.000000    |
|  25%  | 9.000000    |
|  50%  | 20.000000   |
|  75%  | 37.000000   |
|  max  | 2307.000000 |

| Контрольная группа 1 |             |   | Контрольная группа 2 |             |   | Экспериментальная группа |             |
|----------------------|-------------|---|----------------------|-------------|---|--------------------------|-------------|
| count                | 2489.000000 |   | count                | 2520.000000 |   | count                    | 2542.000000 |
| mean                 | 32.214142   |   | mean                 | 30.932540   |   | mean                     | 33.667191   |
| std                  | 65.085668   |   | std                  | 56.304849   |   | std                      | 72.931171   |
| min                  | 1.000000    |   | min                  | 1.000000    |   | min                      | 1.000000    |
| 25%                  | 9.000000    |   | 25%                  | 9.000000    |   | 25%                      | 9.000000    |
| 50%                  | 19.000000   |   | 50%                  | 19.500000   |   | 50%                      | 20.000000   |
| 75%                  | 37.000000   |   | 75%                  | 37.000000   |   | 75%                      | 38.000000   |
| max                  | 1998.000000 |   | max                  | 1768.000000 |   | max                      | 2307.000000 |

Медианное количество событий на пользователя равно 20. Максимальное значение похоже на выброс. В каждую группу попали рекордсмены по количеству событий.
Посмотрим последние перцентили.
```
# Посчитаем с 95 по 99 перцентили 
print(np.percentile(number_of_events['event'], [95, 96, 97, 98, 99])) 
```
```
[ 89.  100.  115.5 136.  200.5]
```
```
print('Пользователей, совершивших более 200 действий =', len(number_of_events.query('event > 200')))
```
```
Пользователей, совершивших более 200 действий = 76
```
Построим гистрограмму распредления числа событий на одного пользователя
```
plt.figure(figsize=(15,5))
plt.hist((df.groupby('user_id')['event'].count()), bins=50, ec="white", range=(1, 200))
plt.grid()
plt.xlabel('События')
plt.ylabel('Пользователи')
plt.title('Число событий на пользователя')
plt.show()
```
![изображение](https://user-images.githubusercontent.com/104757775/203414723-fff2206a-3a4f-4528-949a-065d67b30c7a.png)

Полученный график имеет длинный хвост справа. Визуально различимо - до 100 событий. Далее количество пользователй очень мало.
```
# получим ID самого активного пользователя
number_of_events.sort_values('event').tail(1)
```
|       user_id       | event |
|:-------------------:|:-----:|
| 6304868067479728361 | 2307  |
```
# создадим отдельную переменную для активного пользователя
active_user = df.query('user_id == 6304868067479728361')
```
```
# добавим колонку с номером дня
active_user['day'] = active_user['date'].dt.day
```
```
active_user.groupby('day').agg({'event': 'count'}).reset_index()
```
|   | day | event |
|--:|----:|------:|
| 0 | 1   | 68    |
| 1 | 2   | 2190  |
| 2 | 3   | 18    |
| 3 | 4   | 8     |
| 4 | 5   | 5     |
| 5 | 6   | 4     |
| 6 | 7   | 14    |
```
active_user.head(1)
```
|       |            event |             user_id | event_time | group |            datetime |       date | day |
|------:|-----------------:|--------------------:|-----------:|------:|--------------------:|-----------:|----:|
| 32936 | MainScreenAppear | 6304868067479728361 | 1564682485 | 248   | 2019-08-01 18:01:25 | 2019-08-01 | 1   |

События распределены неравномерно. Большая часть приходится на 2-ой день.
```
active_user.query('day == 2').event.value_counts()
```
```
CartScreenAppear           1070
PaymentScreenSuccessful    1063
OffersScreenAppear           38
MainScreenAppear             19
Name: event, dtype: int64
```
Главный экран отобразился 19 раз.   
Экран выбора товара - 38 событий.   
Переход в корзину - 1070 событий.   
Подтверждение оплаты - 1063 событий.

Если это не технический сбой, тогда мы получили оптового покупателя, который, вероятно, выбирал товар через веб интерфейс, а в момент перехода в корзину автоматически открывалось мобильное приложение. Почти все заказы из корзины были оплачены.

Чтобы исключить технический сбой необходимо проверить суммы оплаты и факт получения товара.

**3.4  Данными за какой период вы располагаете? Найдите максимальную и минимальную дату. Постройте гистограмму по дате и времени. Можно ли быть уверенным, что у вас одинаково полные данные за весь период? Технически в логи новых дней по некоторым пользователям могут «доезжать» события из прошлого — это может «перекашивать данные». Определите, с какого момента данные полные и отбросьте более старые. Данными за какой период времени вы располагаете на самом деле?*
**
```
print('Период исследования -', df['date'].max() - df['date'].min())
print('Первая дата лога -', df['date'].min())
print('Последняя дата лога -', df['date'].max())
```
```
Период исследования - 13 days 00:00:00
Первая дата лога - 2019-07-25 00:00:00
Последняя дата лога - 2019-08-07 00:00:00
```
Мы видим, что файл с логами содержит информацию о событиях за 14 деней.
Посмотрим, как распределены события про датам.
```
# построим столбчатую гистограмму 
df.date.hist(bins=14, ec="white", grid=False, figsize=(15,5)) \
    .set_title('Распределение числа событий по датам');
```
![изображение](https://user-images.githubusercontent.com/104757775/203416089-132ff16c-b61b-498d-943f-2b11d26ffca8.png)

Почти все данные распределены в последней неделе исследования.   
Вероятно, из-за технической особенности в логи новых дней загружаются события из прошлого.
```
print('Количество событий в 1-ю неделю =', df.query('date < "2019-08-01"').shape [0])
print('Доля событий 1-ой недели =',  "{:.1%}".format(df.query('date < "2019-08-01"').shape [0] / events))
```
```
Количество событий в 1-ю неделю = 2826
Доля событий 1-ой недели = 1.2%
```
Посмотрим, с какого момента логи событий начали активно сохраняться. Для этого построим почасовую гистограмму за 31 июля.
```
df.query('"2019-08-01" > date > "2019-07-30"') \
    .pivot_table(index='datetime', values='event', aggfunc='count') \
    .reset_index() \
    .datetime.hist(bins=24, ec="white", grid=False, figsize=(15,5)) \
    .set_title('Распределение событий 31 июля по часам');
```
![изображение](https://user-images.githubusercontent.com/104757775/203416389-864562dc-962d-4c15-8836-3d7049eb7763.png)

Активная запись логов начинается после 21-00. Отбросим данные до этого времени.
```
df.head(1)
```
|   |            event |             user_id | event_time | group |            datetime |       date |
|--:|-----------------:|--------------------:|-----------:|------:|--------------------:|-----------:|
| 0 | MainScreenAppear | 4575588528974610257 | 1564029816 | 246   | 2019-07-25 04:43:36 | 2019-07-25 |
```
# отбросим ненужный период
data = df.query('event_time > 1564596000')

# проверим кол-во удалённых данных
events - data.shape [0]
```
```
1762
```
*Не смог применить метод query к колонке `datetime`, поллучаю ошибку `not supported between instances of 'type' and 'str'`. Через Timestamp To Date Converter получил, что для даты и времени 2019-07-31 21:00:00 соответствует 1564596000 timestamp.*

**3.5  Много ли событий и пользователей вы потеряли, отбросив старые данные?**
```
print('Пользователи:')
print('Было -', users)
print('Осталось -', len(data['user_id'].unique()))
print('Исключили -', users-len(data['user_id'].unique()))
print('Доля исключённых пользователей -',"{:.1%}".format((users-len(data['user_id'].unique()))/users))
print()
print('События:')
print('Было -', events)
print('Осталось -', data['event'].count())
print('Исключили -', events-data['event'].count())
print('Доля исключённых пользователей -',"{:.1%}".format((events-data['event'].count())/events))
```
```
Пользователи:
Было - 7551
Осталось - 7539
Исключили - 12
Доля исключённых пользователей - 0.2%

События:
Было - 243713
Осталось - 241951
Исключили - 1762
Доля исключённых пользователей - 0.7%
```
**3.6  Проверьте, что у вас есть пользователи из всех трёх экспериментальных групп.**
```
data.group.value_counts()
```
```
248    84949
246    79632
247    77370
Name: group, dtype: int64
```
Пользователи на месте.   
Напомним обозначение номеров эксперимента: 246 и 247 — контрольные группы, а 248 — экспериментальная.

### 4.  Изучите воронку событий

**4.1  Посмотрите, какие события есть в логах, как часто они встречаются. Отсортируйте события по частоте.**
```
data.event.value_counts()
```
```
MainScreenAppear           118005
OffersScreenAppear          46577
CartScreenAppear            42383
PaymentScreenSuccessful     33976
Tutorial                     1010
Name: event, dtype: int64
```
Получили 5 типов событий.

**4.2  Посчитайте, сколько пользователей совершали каждое из этих событий. Отсортируйте события по числу пользователей. Посчитайте долю пользователей, которые хоть раз совершали событие.**
```
# Посчитаем, сколько пользователей совершали каждое событий
df_event = data.groupby('event') \
    .agg({'user_id': 'nunique'}) \
    .rename(columns={'user_id': 'users'}) \
    .reset_index() \
    .sort_values(by='users', ascending=False)

# Посчитаем долю пользователей
df_event['user_%'] = (df_event['users'] * 100 / len(data['user_id'].unique())).round(1)

df_event.style.format({'user_%': '{:.1f}%'})
```
|       |        **event**        | **users** | **user_%** |
|:-----:|:-----------------------:|:---------:|:----------:|
| **1** | MainScreenAppear        | 7424      | 98.5%      |
| **2** | OffersScreenAppear      | 4600      | 61.0%      |
| **0** | CartScreenAppear        | 3736      | 49.6%      |
| **3** | PaymentScreenSuccessful | 3540      | 47.0%      |
| **4** | Tutorial                | 843       | 11.2%      |

**4.3  Предположите, в каком порядке происходят события. Все ли они выстраиваются в последовательную цепочку? Их не нужно учитывать при расчёте воронки.**

Выполнив сортировку событий по частоте, мы получили последовательность, с которой сталкиваются пользователи.   
Самое популярное `MainScreenAppear` (118 108 событий) - появление главного экрана. Взаимодействие с интерфейсом мобильного приложения всегда начинается с главного экрана. В нашем случае на главный экран попали 98.5% пользователей. Значит 115 позователей не попали на главный экран, возможно во время предобработки данных мы исключили события просмотра главного экрана. Далее пользователь, ознакомившись с текущими предложениями и скидками или покидает приложение или начинает оформление заказа `OffersScreenAppear` (46 594 событий). Выбрав необходимый товар, пользователь переходит в корзину `CartScreenAppear` (42 446 событий). Мы видим, что не все, кто выбирал товар дошли до корзины. Вероятно, Пользователь не нашел интересующий товар и отказался полностью от всего заказа, или во время взаимодействия с приложением пользователя отвлекли (например, поступил звонок), после этого к приложению не вернулись. Стоит проверить выдаёт ли наше приложение push уведомление о неоформленном заказе. Затем пользователь производит оплату `PaymentScreenSuccessful` (34 171 событий). Однако, не все пользователи перешедшие в корзину оплачивают заказ. Причиной может быть непринятый Промо код или не устраивает срок доставки.    
Небольшое число событий приходится на обращение к справочному разделу приложения `Tutorial` (1 044 событий). В данном случае нельзя определить порядок указанного события. Пользователь может на любом этапе взаимодействия с приложением обратиться за поддержкой.
```
# создадим Series с пользователями попавшими на главный экран
users_main_screen = data.loc[data['event'] == 'MainScreenAppear', 'user_id']

# создадим переменную с пользователями не попавшими на главный экран
tmp = data.query('user_id not in @users_main_screen')

print('Количество пользователей, пропустивших главный экран =', len(tmp.user_id.unique()))
print()

users_main_screen_before = df.loc[df['event'] == 'MainScreenAppear', 'user_id']
tmp2=df.query('user_id not in @users_main_screen_before')
print('Количество всех пользователей, пропустивших главный экран =', len(tmp2.user_id.unique()))
```
```
Количество пользователей, пропустивших главный экран = 115

Количество всех пользователей, пропустивших главный экран = 112
```
В результате предобработки данных мы потеряти логи с посещением главного экрана у 3-х пользователей.   
Или оформлять заказ возможно минуя главный экран или логирование действий 112 пользователей началось после того, как они посетили главный экран.

**4.4  По воронке событий посчитайте, какая доля пользователей проходит на следующий шаг воронки (от числа пользователей на предыдущем). То есть для последовательности событий A → B → C посчитайте отношение числа пользователей с событием B к количеству пользователей с событием A, а также отношение числа пользователей с событием C к количеству пользователей с событием B.**

```
df_event
```
|       |        **event**        | **users** | **user_%** |
|:-----:|:-----------------------:|:---------:|:----------:|
| **1** | MainScreenAppear        | 7424      | 98.5%      |
| **2** | OffersScreenAppear      | 4600      | 61.0%      |
| **0** | CartScreenAppear        | 3736      | 49.6%      |
| **3** | PaymentScreenSuccessful | 3540      | 47.0%      |
| **4** | Tutorial                | 843       | 11.2%      |
```
# Построим диаграмму воронки
fig = go.Figure(go.Funnel(
    x = df_event['users'], 
    y = df_event.loc[df_event['event'] != 'Tutorial', 'event'],
    textposition = "inside",
    textinfo = "value+percent initial+percent previous"))
fig.show()
```
![изображение](https://user-images.githubusercontent.com/104757775/203419386-512ab4e8-70c7-4daa-818b-e090b62b6dfc.png)

Построим варонку в разрезе по гркппам.
```
funnel_by_groups = data.groupby(['event', 'group']) \
    .agg({'user_id': 'nunique'}) \
    .reset_index() \
    .sort_values('user_id', ascending=False)
```
```
fig = px.funnel(funnel_by_groups, x='user_id', y='event', color='group')
fig.show()
```
![изображение](https://user-images.githubusercontent.com/104757775/203419537-7d8b0a41-8f67-4f8b-888e-4f6c5a2446c7.png)

**4.5  На каком шаге теряете больше всего пользователей?**

Наибольшее число пользователей пропадает при переходе с главного экрана к оформлению заказа.

**4.6  Какая доля пользователей доходит от первого события до оплаты?**
```
# Число пользователей первого события
first_level = int(df_event.loc[df_event['event'] == 'MainScreenAppear', 'users'])

# Число оплативших пользователей
last_level = int(df_event.loc[df_event['event'] == 'PaymentScreenSuccessful', 'users'])

print('Доля оплативших пользователей =', "{:.1%}".format(last_level / first_level))
```
```
Доля оплативших пользователей = 47.7%
```
**Вывод**   
Имеем пять типов событий. Из них в воронку входят четыре. Наибольшее число пользователей теряется при переходе с первого на второе событие. Доля оплативших пользователей почти половина от тех, кто начал пользоваться мобильным приложением.

### 5.  Изучите результаты эксперимента

**5.1  Сколько пользователей в каждой экспериментальной группе?**
```
group = data.groupby('group').agg({'user_id': 'nunique'}).reset_index().rename(columns={'user_id': 'users'})
group['type'] = ['контрольная группа 1', 'контрольная группа 2', 'экпериментальная группа']
group
```
|       | **group** | **users** |                **type** |
|------:|----------:|----------:|------------------------:|
| **0** | 246       | 2484      | контрольная группа 1    |
| **1** | 247       | 2517      | контрольная группа 2    |
| **2** | 248       | 2538      | экпериментальная группа |

**5.2  Есть 2 контрольные группы для А/А-эксперимента, чтобы проверить корректность всех механизмов и расчётов. Проверьте, находят ли статистические критерии разницу между выборками 246 и 247.**

Чтобы узнать есть ли статистические критерии разницу между выборками 246 и 247 воспользуемся гипотезой о равенстве долей.   
Создадим датафрейм с разбивкой событий по группам.
```
group_event = df.pivot_table(
    index='event',
    columns='group',
    values='user_id',
    aggfunc='nunique') \
        .reset_index() \
        .merge(df_event) \
        .sort_values(by='users', ascending=False)
group_event
```
|       |               **event** | **246** | **247** | **248** | **users** | **user_%** |
|------:|------------------------:|--------:|--------:|--------:|----------:|-----------:|
| **1** | MainScreenAppear        | 2456    | 2482    | 2501    | 7424      | 98.5       |
| **2** | OffersScreenAppear      | 1545    | 1530    | 1538    | 4600      | 61.0       |
| **0** | CartScreenAppear        | 1270    | 1240    | 1239    | 3736      | 49.6       |
| **3** | PaymentScreenSuccessful | 1202    | 1160    | 1185    | 3540      | 47.0       |
| **4** | Tutorial                | 279     | 286     | 282     | 843       | 11.2       |

Проведём z-тест    
![изображение](https://user-images.githubusercontent.com/104757775/203420214-fa094811-df48-467f-813f-85f6a0acaed0.png)

```
for i in group_event.index:
    alpha = .01 # критический уровень статистической значимости
    p1 = group_event[246][i] / group_event[246].sum()
    # пропорция успехов во второй группе:
    p2 = group_event[247][i] / group_event[247].sum()
    # пропорция успехов в комбинированном датасете:
    p_combined = ((group_event[246][i] + group_event[247][i]) / 
                 (group_event[246].sum() + group_event[247].sum()))
    # разница пропорций в датасетах
    difference = p1 - p2
    # считаем статистику в ст.отклонениях стандартного нормального распределения
    z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * 
              (1/group_event[246].sum() + 1/group_event[247].sum()))
    # задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
    distr = stats.norm(0, 1) 
    p_value = (1 - distr.cdf(abs(z_value))) * 2
    print('{} p-значение: {}'.format(group_event['event'][i], p_value))
    if (p_value < alpha):
        print("Отвергаем нулевую гипотезу: между долями есть значимая разница")
    else:
        print("Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными")
    print()
```
```
MainScreenAppear p-значение: 0.412360370535906
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

OffersScreenAppear p-значение: 0.9565370626180498
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

CartScreenAppear p-значение: 0.6592657639476591
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

PaymentScreenSuccessful p-значение: 0.4611848531171103
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

Tutorial p-значение: 0.6903463676090333
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными
```
Ни в одном событии статистически значимого различия между двумя контрольными группами нет.

**5.3  Выберите самое популярное событие. Посчитайте число пользователей, совершивших это событие в каждой из контрольных групп. Посчитайте долю пользователей, совершивших это событие. Проверьте, будет ли отличие между группами статистически достоверным. Проделайте то же самое для всех других событий (удобно обернуть проверку в отдельную функцию). Можно ли сказать, что разбиение на группы работает корректно?**
```
group.index = group['group'].tolist()
```
```
group_event['part_of_a1'] = (group_event[246] * 100 / group['users'][246]).round(1)
group_event['part_of_a'] = (group_event[247] * 100 / group['users'][247]).round(1)
group_event['part_of_b'] = (group_event[248] * 100 / group['users'][248]).round(1)
group_event
```
|       |               **event** | **246** | **247** | **248** | **users** | **user_%** | **part_of_a1** | **part_of_a** | **part_of_b** |
|------:|------------------------:|--------:|--------:|--------:|----------:|-----------:|---------------:|--------------:|--------------:|
| **1** | MainScreenAppear        | 2456    | 2482    | 2501    | 7424      | 98.5       | 98.9           | 98.6          | 98.5          |
| **2** | OffersScreenAppear      | 1545    | 1530    | 1538    | 4600      | 61.0       | 62.2           | 60.8          | 60.6          |
| **0** | CartScreenAppear        | 1270    | 1240    | 1239    | 3736      | 49.6       | 51.1           | 49.3          | 48.8          |
| **3** | PaymentScreenSuccessful | 1202    | 1160    | 1185    | 3540      | 47.0       | 48.4           | 46.1          | 46.7          |
| **4** | Tutorial                | 279     | 286     | 282     | 843       | 11.2       | 11.2           | 11.4          | 11.1          |

**5.4  Аналогично поступите с группой с изменённым шрифтом. Сравните результаты с каждой из контрольных групп в отдельности по каждому событию. Сравните результаты с объединённой контрольной группой. Какие выводы из эксперимента можно сделать?**

Создадим объединённую группу

```
group_event['a_a'] = group_event[246] + group_event[247]
```
```
group
```
|     | group | users |                    type |
|----:|------:|------:|------------------------:|
| 246 | 246   | 2484  | контрольная группа 1    |
| 247 | 247   | 2517  | контрольная группа 2    |
| 248 | 248   | 2538  | экпериментальная группа |

Сравним **первую** контрольную группу с **экспериментальной**
```
for i in group_event.index:
    alpha = .05 # критический уровень статистической значимости
    p1 = group_event[246][i] / group.loc[246, 'users']
    # пропорция успехов во второй группе:
    p2 = group_event[248][i] / group.loc[248, 'users']
    # пропорция успехов в комбинированном датасете:
    p_combined = ((group_event[246][i] + group_event[248][i]) / 
                 (group.loc[246, 'users'] + group.loc[248, 'users']))
    # разница пропорций в датасетах
    difference = p1 - p2
    # считаем статистику в ст.отклонениях стандартного нормального распределения
    z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * 
              (1/group.loc[246, 'users'] + 1/group.loc[248, 'users']))
    # задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
    distr = stats.norm(0, 1) 
    p_value = (1 - distr.cdf(abs(z_value))) * 2
    print('{} p-значение: {}'.format(group_event['event'][i], p_value))
    if (p_value < alpha):
        print("Отвергаем нулевую гипотезу: между долями есть значимая разница")
    else:
        print("Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными")
    print()
```
```
MainScreenAppear p-значение: 0.3000108162876214
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

OffersScreenAppear p-значение: 0.2445041949520088
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

CartScreenAppear p-значение: 0.10176035071256462
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

PaymentScreenSuccessful p-значение: 0.22793704327759867
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

Tutorial p-значение: 0.8919466789896047
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными
```
Сравним **вторую** контрольную группу с **экспериментальной**
```
for i in group_event.index:
    alpha = .05 # критический уровень статистической значимости
    p1 = group_event[247][i] / group.loc[247, 'users']
    # пропорция успехов во второй группе:
    p2 = group_event[248][i] / group.loc[248, 'users']
    # пропорция успехов в комбинированном датасете:
    p_combined = ((group_event[247][i] + group_event[248][i]) / 
                 (group.loc[247, 'users'] + group.loc[248, 'users']))
    # разница пропорций в датасетах
    difference = p1 - p2
    # считаем статистику в ст.отклонениях стандартного нормального распределения
    z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * 
              (1/group.loc[247, 'users'] + 1/group.loc[248, 'users']))
    # задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
    distr = stats.norm(0, 1) 
    p_value = (1 - distr.cdf(abs(z_value))) * 2
    print('{} p-значение: {}'.format(group_event['event'][i], p_value))
    if (p_value < alpha):
        print("Отвергаем нулевую гипотезу: между долями есть значимая разница")
    else:
        print("Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными")
    print()
```
```
MainScreenAppear p-значение: 0.8399975923992675
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

OffersScreenAppear p-значение: 0.8913072139638907
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

CartScreenAppear p-значение: 0.7505696632724148
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

PaymentScreenSuccessful p-значение: 0.6669492604688005
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

Tutorial p-значение: 0.7769976972403507
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными
```
Сравним **объединённую** контрольную группу с **экспериментальной**
```
for i in group_event.index:
    alpha = .05 # критический уровень статистической значимости
    p1 = group_event['a_a'][i] / (group.loc[246, 'users'] + group.loc[247, 'users'])
    # пропорция успехов во второй группе:
    p2 = group_event[248][i] / group.loc[248, 'users']
    # пропорция успехов в комбинированном датасете:
    p_combined = ((group_event['a_a'][i] + group_event[248][i]) / 
                 (group.loc[246, 'users'] + group.loc[247, 'users'] + group.loc[248, 'users']))
    # разница пропорций в датасетах
    difference = p1 - p2
    # считаем статистику в ст.отклонениях стандартного нормального распределения
    z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * 
              (1/(group.loc[246, 'users'] + group.loc[247, 'users']) + 1/group_event[248][i]))
    # задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
    distr = stats.norm(0, 1) 
    p_value = (1 - distr.cdf(abs(z_value))) * 2
    print('{} p-значение: {}'.format(group_event['event'][i], p_value))
    if (p_value < alpha):
        print("Отвергаем нулевую гипотезу: между долями есть значимая разница")
    else:
        print("Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными")
    print()
```
```
MainScreenAppear p-значение: 0.47956403314700324
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

OffersScreenAppear p-значение: 0.5316284958396365
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

CartScreenAppear p-значение: 0.38720859990640855
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

PaymentScreenSuccessful p-значение: 0.7376147687393944
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными

Tutorial p-значение: 0.9230776927361368
Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными
```
Статистически значимого различия между контрольными и экспериментальными группами нет.

**5.5  Какой уровень значимости вы выбрали при проверке статистических гипотез выше? Посчитайте, сколько проверок статистических гипотез вы сделали. При уровне значимости 0.1 каждый десятый раз можно получать ложный результат. Какой уровень значимости стоит применить? Если вы хотите изменить его, проделайте предыдущие пункты и проверьте свои выводы.**

При проведении А/А теста тосность должна быть выше, поэтому критический уровень статистической значимости равен 1%   
Чтобы не получить ложный результат при А/В тесте критический уровень статистической значимости установлен 5%

# Вывод

Для изучения использовались логи мобильного приложения за две недели. Однако, количество данных за первую неделю очень мало.   

Журнал содержит пять типов событий:
- `MainScreenAppear` - пользователь попал на главный экран
- `OffersScreenAppear` - экран оформления заказа
- `CartScreenAppear`- экран корзины
- `PaymentScreenSuccessful` - уведомление об успешной оплате
- `Tutorial` - помощь / руководство

В воронке действий пользователей используются первые четыре. `Tutorial` является информационным.

Изучив варонку, стало понятно, что большинство пользователей мы теряем после первого шага.

![изображение](https://user-images.githubusercontent.com/104757775/203421724-5bd0804f-703b-4ebb-b4ba-d8ecf707a74a.png)

Не каждый пользователь, запустивший приложение делает заказ. Доля оплативших пользователей от общего числа посетителей составляет 47.7%. Почти каждый второй пользователь мобильного приоржения делает заказ.

А/А тест показал, что статистически значимого различия между контрольными группами нет и можно приступать к А/В тесту.

Чтобы не получить ложный результат при А/В тесте критический уровень статистической значимости установлен 0.5%. В результате теста не получили статистически значимого различия между контрольными и экспериментальными группами. Следовательно изменение шрифтов в приложении не повлияет на поведение пользователей. 
