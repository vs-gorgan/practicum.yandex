# Описание проекта.

Вы работаете аналитиком в Яндекс.Дзене. Почти всё ваше время занимает анализ пользовательского взаимодействия с карточками статей.

Каждую карточку определяют её тема и источник (у него тоже есть тема). Примеры тем: «Красота и здоровье», «Россия», «Путешествия».

Пользователей системы характеризует возрастная категория. Скажем, «26-30» или «45+».

Есть три способа взаимодействия пользователей с системой:

-    Карточка отображена для пользователя (show);
-    Пользователь кликнул на карточку (click);
-    Пользователь просмотрел статью карточки (view).

Каждую неделю начинающие менеджеры Денис и Валерия задают вам одни и те же вопросы:

-    Сколько взаимодействий пользователей с карточками происходит в системе с разбивкой по темам карточек?
-    Как много карточек генерируют источники с разными темами?
-    Как соотносятся темы карточек и темы источников?

На шестую неделю работы вы решаете, что процесс пора автоматизировать. Для Дениса и Валерии нужно сделать дашборд.

Дашборд будет основываться на пайплайне, который будет брать данные из таблицы, в которых хранятся сырые данные, трансформировать данные и укладывать их в агрегирующую таблицу. Пайплайн будет разработан для вас дата-инженерами.

Пообщавшись с менеджерами и администраторами баз данных, вы написали краткое ТЗ:

-    Бизнес-задача: анализ взаимодействия пользователей с карточками Яндекс.Дзен;
-    Насколько часто предполагается пользоваться дашбордом: не реже, чем раз в неделю;
-    Кто будет основным пользователем дашборда: менеджеры по анализу контента;
-    Состав данных для дашборда:
     -   История событий по темам карточек (два графика - абсолютные числа и процентное соотношение);
     -   Разбивка событий по темам источников;
     -   Таблица соответствия тем источников темам карточек;
-    По каким параметрам данные должны группироваться:
     -   Дата и время;
     -   Тема карточки;
     -   Тема источника;
     -   Возрастная группа;
-    Характер данных:
     -   История событий по темам карточек — абсолютные величины с разбивкой по минутам;
     -   Разбивка событий по темам источников — относительные величины (% событий);
     -   Соответствия тем источников темам карточек - абсолютные величины;
-    Важность: все графики имеют равную важность;
-    Источники данных для дашборда: дата-инженеры обещали подготовить для вас агрегирующую таблицу dash_visits. Вот её структура:
     -   `record_id` — первичный ключ,
     -   `item_topic` — тема карточки,
     -   `source_topic` — тема источника,
     -   `age_segment` — возрастной сегмент,
     -   `dt` — дата и время,
     -   `visits` — количество событий.
-    Таблица хранится в специально подготовленной для вас базе данных zen;
-    Частота обновления данных: один раз в сутки, в полночь по UTC;
-    Какие графики должны отображаться и в каком порядке, какие элементы управления должны быть на дашборде (макет дашборда):

![изображение](https://user-images.githubusercontent.com/104757775/208314899-c82f8469-645a-4f71-9191-9d00d78958ed.png)

Создим коннекцию к базе
```
# импортируем библиотеки
import pandas as pd
from sqlalchemy import create_engine

db_config = {'user': 'praktikum_student', # имя пользователя
            'pwd': 'Sdf4$2;d-d30pp', # пароль
            'host': 'rc1b-wcoijxj3yxfsf3fs.mdb.yandexcloud.net',
            'port': 6432, # порт подключения
            'db': 'data-analyst-zen-project-db'} # название базы данных

connection_string = 'postgresql://{}:{}@{}:{}/{}'.format(db_config['user'],
                                                db_config['pwd'],
                                                db_config['host'],
                                                db_config['port'],
                                                db_config['db'])

engine = create_engine(connection_string)
```
Коннекция к базе хранится в переменной engine

```
# Формируем sql-запрос.
query = ''' SELECT *
            FROM dash_visits
        '''
```
Выполняем запрос и сохраняем результат выполнения в DataFrame.    
Sqlalchemy автоматически установит названия колонок
```
dash_visits = pd.io.sql.read_sql(query, con = engine)
```
<code>[ссылка](https://colab.research.google.com/drive/1CDUiUL1NmqVJi63BBeTQ-na3NCZXgV8c?usp=sharing#scrollTo=W3QpY_b1hwye)</code> на тетрадку автоматизации.
